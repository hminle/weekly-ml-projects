{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchnet.meter import AverageValueMeter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'mnist' from '/home/hminle/Github/weekly-ml-projects/gan/mnist.py'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mnist; importlib.reload(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define parser arguments\n",
    "parser = {\n",
    "    \"batch_size\": 64,\n",
    "    \"epochs\": 10,\n",
    "    \"no_cuda\": False,\n",
    "    \"seed\": 1,\n",
    "    \"log_interval\": 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parse arguments for  model\n",
    "args = argparse.Namespace(**parser) # parse arguments\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    mnist.MNIST('../data', train=True, transform=transforms.ToTensor()),\n",
    "    batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    mnist.MNIST('../data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=args.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mb_size = args.batch_size\n",
    "Z_dim = 100\n",
    "X_dim = 784\n",
    "y_dim = 10\n",
    "h_dim = 128\n",
    "c = 0\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    out_dim = size[1]\n",
    "    xavier_stddev = 1. / np.sqrt((in_dim + out_dim) / 2.)\n",
    "    return Variable(torch.randn(*size) * xavier_stddev, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Wzh = xavier_init(size=[Z_dim, h_dim])\n",
    "bzh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
    "\n",
    "Whx = xavier_init(size=[h_dim, X_dim])\n",
    "bhx = Variable(torch.zeros(X_dim), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def G(z):\n",
    "    h = F.relu(z @ Wzh + bzh.repeat(z.size(0), 1))\n",
    "    X = F.sigmoid(h @ Whx + bhx.repeat(h.size(0), 1))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DISCRIMINATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Wxh = xavier_init(size=[X_dim, h_dim])\n",
    "bxh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
    "\n",
    "Why = xavier_init(size=[h_dim, 1])\n",
    "bhy = Variable(torch.zeros(1), requires_grad=True)\n",
    "\n",
    "\n",
    "def D(X):\n",
    "    h = F.relu(X @ Wxh + bxh.repeat(X.size(0), 1))\n",
    "    y = F.sigmoid(h @ Why + bhy.repeat(h.size(0), 1))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_params = [Wzh, bzh, Whx, bhx]\n",
    "D_params = [Wxh, bxh, Why, bhy]\n",
    "params = G_params + D_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_grad():\n",
    "    for p in params:\n",
    "        p.grad.data.zero_()\n",
    "\n",
    "\n",
    "G_solver = optim.Adam(G_params, lr=1e-3)\n",
    "D_solver = optim.Adam(D_params, lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vis = visdom.Visdom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "        # Sample data\n",
    "        #X.size(0) = batch_size\n",
    "    D_losses = AverageValueMeter()\n",
    "    G_losses = AverageValueMeter()\n",
    "    for X, _ in train_loader:\n",
    "        ones_label = Variable(torch.ones(X.size(0)))\n",
    "        zeros_label = Variable(torch.zeros(X.size(0)))\n",
    "        \n",
    "        z = Variable(torch.randn(X.size(0), Z_dim))\n",
    "        X = Variable(X.view(-1, 784))\n",
    "\n",
    "        # Dicriminator forward-loss-backward-update\n",
    "        G_sample = G(z) # X_fake\n",
    "        D_real = D(X)\n",
    "        D_fake = D(G_sample)\n",
    "\n",
    "        D_loss_real = F.binary_cross_entropy(D_real, ones_label) # compare D_real with 1\n",
    "        D_loss_fake = F.binary_cross_entropy(D_fake, zeros_label) # compare D_fake with 0\n",
    "        D_loss = D_loss_real + D_loss_fake\n",
    "\n",
    "        # Housekeeping - reset gradient\n",
    "        reset_grad()\n",
    "        # Tinh dao ham cua D_loss vs cac Variable require_grad = true\n",
    "        D_loss.backward()\n",
    "        # update params\n",
    "        D_solver.step()\n",
    "\n",
    "\n",
    "\n",
    "        # Generator forward-loss-backward-update\n",
    "        z = Variable(torch.randn(X.size(0), Z_dim))\n",
    "        G_sample = G(z)\n",
    "        D_fake = D(G_sample)\n",
    "\n",
    "        G_loss = F.binary_cross_entropy(D_fake, ones_label) # Compare D_fake with 1\n",
    "\n",
    "        # Housekeeping - reset gradient\n",
    "        reset_grad()\n",
    "        G_loss.backward()\n",
    "        G_solver.step()\n",
    "        \n",
    "        D_losses.add(D_loss.data[0]*X.size(0), X.size(0))\n",
    "        G_losses.add(G_loss.data[0]*X.size(0), X.size(0))\n",
    "    print('Epoch-{}; D_loss: {}; G_loss: {}'\n",
    "        .format(epoch, D_losses.value()[0], G_losses.value()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(samples, epoch):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "    if not os.path.exists('out_GAN/'):\n",
    "        os.makedirs('out_GAN/')\n",
    "\n",
    "    plt.savefig('out_GAN/{}.png'.format(str(epoch).zfill(3)), bbox_inches='tight')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-0; D_loss: 0.7881988826433818; G_loss: 1.9799039277394612\n",
      "Epoch-1; D_loss: 0.7781565422693888; G_loss: 1.9704048128763834\n",
      "Epoch-2; D_loss: 0.7646393604596455; G_loss: 2.027835792605082\n",
      "Epoch-3; D_loss: 0.7684109745661417; G_loss: 2.058323233795166\n",
      "Epoch-4; D_loss: 0.7580886743863424; G_loss: 2.045337483215332\n",
      "Epoch-5; D_loss: 0.7541149898846944; G_loss: 2.080440088526408\n",
      "Epoch-6; D_loss: 0.7459175700505575; G_loss: 2.108483600997925\n",
      "Epoch-7; D_loss: 0.7382791342099507; G_loss: 2.143351516977946\n",
      "Epoch-8; D_loss: 0.7307715403556824; G_loss: 2.171455207443237\n",
      "Epoch-9; D_loss: 0.7228711834271749; G_loss: 2.1784596199035646\n"
     ]
    }
   ],
   "source": [
    "#Before training, draw one figure\n",
    "z = Variable(torch.randn(mb_size, Z_dim))\n",
    "samples = G(z).data.numpy()[:16]\n",
    "plot(samples, 999)\n",
    "\n",
    "for epoch in range(0,args.epochs):\n",
    "    train(epoch)\n",
    "    z = Variable(torch.randn(mb_size, Z_dim))\n",
    "    samples = G(z).data.numpy()[:16]\n",
    "    plot(samples, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
